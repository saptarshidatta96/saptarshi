{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_cnn_cifar100.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk9GOE9BJCRg"
      },
      "source": [
        "# Basic CNN and MLP implementation using PyTorch\n",
        "\n",
        "This is a basic implementation of CNN and MLP in the PyTorch framework. We haven't done anything fancy with the NN architecture. However, make sure to check the preprocessing area.\n",
        "\n",
        "We have used the coarse lebels of Cifar-100 and also implemented a sub-routine to determine the mean and standard deviation per channel of the input CIFAR-100 data. This approach will be much better than guessing and searching Research Papers for the appropriate digits.\n",
        "\n",
        "Other than this, we have provided teh used with an option to run either MLP implementation or CNN implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebys4L3f_4Rs"
      },
      "source": [
        "##Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inHVt_KANN5O"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision.datasets import CIFAR100\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD-tqSLFSTD6"
      },
      "source": [
        "##Preprocessing Area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpImB_FpBySB"
      },
      "source": [
        "class CIFAR100coarse(CIFAR100):\n",
        "  def __init__(self, root, train = True, transform = None, target_transform=None, download = False):\n",
        "\n",
        "    super(CIFAR100coarse, self).__init__(root, train, transform, target_transform, download)\n",
        "    coarse_labels = np.array([ 4,  1, 14,  8,  0,  6,  7,  7, 18,  3,\n",
        "                               3, 14,  9, 18,  7, 11,  3,  9,  7, 11,\n",
        "                               6, 11,  5, 10,  7,  6, 13, 15,  3, 15, \n",
        "                               0, 11,  1, 10, 12, 14, 16,  9, 11,  5,\n",
        "                               5, 19,  8,  8, 15, 13, 14, 17, 18, 10,\n",
        "                              16, 4, 17,  4,  2,  0, 17,  4, 18, 17,\n",
        "                              10, 3,  2, 12, 12, 16, 12,  1,  9, 19, \n",
        "                               2, 10,  0,  1, 16, 12,  9, 13, 15, 13,\n",
        "                              16, 19,  2,  4,  6, 19,  5,  5,  8, 19,\n",
        "                              18,  1,  2, 15,  6,  0, 17,  8, 14, 13])\n",
        "    \n",
        "    self.targets = coarse_labels[self.targets]\n",
        "\n",
        "    self.classes = [['beaver', 'dolphin', 'otter', 'seal', 'whale'],\n",
        "                    ['aquarium_fish', 'flatfish', 'ray', 'shark', 'trout'],\n",
        "                    ['orchid', 'poppy', 'rose', 'sunflower', 'tulip'],\n",
        "                    ['bottle', 'bowl', 'can', 'cup', 'plate'],\n",
        "                    ['apple', 'mushroom', 'orange', 'pear', 'sweet_pepper'],\n",
        "                    ['clock', 'keyboard', 'lamp', 'telephone', 'television'],\n",
        "                    ['bed', 'chair', 'couch', 'table', 'wardrobe'],\n",
        "                    ['bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach'],\n",
        "                    ['bear', 'leopard', 'lion', 'tiger', 'wolf'],\n",
        "                    ['bridge', 'castle', 'house', 'road', 'skyscraper'],\n",
        "                    ['cloud', 'forest', 'mountain', 'plain', 'sea'],\n",
        "                    ['camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo'],\n",
        "                    ['fox', 'porcupine', 'possum', 'raccoon', 'skunk'],\n",
        "                    ['crab', 'lobster', 'snail', 'spider', 'worm'],\n",
        "                    ['baby', 'boy', 'girl', 'man', 'woman'],\n",
        "                    ['crocodile', 'dinosaur', 'lizard', 'snake', 'turtle'],\n",
        "                    ['hamster', 'mouse', 'rabbit', 'shrew', 'squirrel'],\n",
        "                    ['maple_tree', 'oak_tree', 'palm_tree', 'pine_tree', 'willow_tree'],\n",
        "                    ['bicycle', 'bus', 'motorcycle', 'pickup_truck', 'train'],\n",
        "                    ['lawn_mower', 'rocket', 'streetcar', 'tank', 'tractor']]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwuluIvzQozs"
      },
      "source": [
        "def mean_std():\n",
        "  transform = transforms.Compose([transforms.ToTensor()])\n",
        "  data_set = CIFAR100coarse(root = './data', train = True, transform = transform, target_transform=None, download = True)\n",
        "  train_loader = torch.utils.data.DataLoader(data_set, batch_size = 4, shuffle=True)\n",
        "  images, labels = iter(train_loader).next()\n",
        "  numpy_images = images.numpy()\n",
        "  per_image_mean = np.mean(numpy_images, axis=(2,3))\n",
        "  per_image_std = np.std(numpy_images, axis=(2,3))\n",
        "  per_channel_mean = np.mean(per_image_mean, axis=0)\n",
        "  per_channel_std = np.mean(per_image_std, axis=0)\n",
        "\n",
        "  return per_channel_mean, per_channel_std"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxN-SY9xNkH0"
      },
      "source": [
        "def cifar_preprocessor(batch_size, test_shuffle = False):\n",
        "  per_channel_mean, per_channel_std = mean_std()\n",
        "  transform =transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean = per_channel_mean, std = per_channel_std)])\n",
        "\n",
        "  train_set = CIFAR100coarse(root = './data', train = True, transform = transform, target_transform=None, download = True)\n",
        "  train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "  test_set = CIFAR100coarse(root = './data', train = True, transform = transform, target_transform=None, download = True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size, shuffle = test_shuffle)\n",
        "\n",
        "  return train_loader, test_loader, train_set, test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNgb3rd3SZRC"
      },
      "source": [
        "##MLP implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2fvF1rzZv4M"
      },
      "source": [
        "class MLP_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    '''\n",
        "    Check this link for nn.Linear: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "    '''\n",
        "    super(MLP_network, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(3072, 2000)\n",
        "    self.fc2 = torch.nn.Linear(2000, 1500)\n",
        "    self.fc3 = torch.nn.Linear(1500, 1000)\n",
        "    self.fc4 = torch.nn.Linear(1000, 800)\n",
        "    self.fc5 = torch.nn.Linear(800, 500)\n",
        "    self.fc6 = torch.nn.Linear(500, 200)\n",
        "    self.out = torch.nn.Linear(200, 20)\n",
        "\n",
        "  def forward(self, t):\n",
        "    #Layer1\n",
        "    t = F.relu(self.fc1(t))\n",
        "    #Layer2\n",
        "    t = F.relu(self.fc2(t))\n",
        "    #Layer3\n",
        "    t = F.relu(self.fc3(t))\n",
        "    #Layer4\n",
        "    t = F.relu(self.fc4(t))\n",
        "    #Layer5\n",
        "    t = F.relu(self.fc5(t))\n",
        "    #Layer6\n",
        "    t = F.relu(self.fc6(t))\n",
        "    #Layer7\n",
        "    t = self.out(t)\n",
        "    return t "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95F4PvW5SdiK"
      },
      "source": [
        "##CNN Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUz3OlVRXWuJ"
      },
      "source": [
        "class CNN_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_network,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "    self.out = nn.Linear(in_features=84, out_features=20)\n",
        "\n",
        "  def forward(self, t):\n",
        "    #Layer 1\n",
        "    t = t\n",
        "    #Layer 2\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)#output shape : (6,14,14)\n",
        "    #Layer 3\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)#output shape : (16,5,5)\n",
        "    #Layer 4\n",
        "    t = t.reshape(-1, 16*5*5)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)#output shape : (1,120)\n",
        "    #Layer 5\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)#output shape : (1, 84)\n",
        "    #Layer 6/ Output Layer\n",
        "    t = self.out(t)#output shape : (1, 20)\n",
        "\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEiP4W5h_hk2"
      },
      "source": [
        "##Training Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgYV6CiAi_Iw"
      },
      "source": [
        "def train_nn(model, train_loader, optimizer, i):\n",
        "  print('>>> Training Start >>>')\n",
        "  for epoch in range(30):\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    for batch in train_loader:\n",
        "      images, labels = batch\n",
        "      if i == 1:\n",
        "        images = images.reshape(-1, 32*32*3) \n",
        "      predictions = model(images)\n",
        "      loss = F.cross_entropy(predictions, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss = total_loss + loss.item()\n",
        "      total_correct = total_correct + predictions.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "    print('epoch:', epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
        "\n",
        "  print('>>> Training Complete >>>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP2F6fie_kmB"
      },
      "source": [
        "##Prediction Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIcX9Gt39PFV"
      },
      "source": [
        "@torch.no_grad()\n",
        "def get_all_preds(model, loader, i):\n",
        "  all_preds = torch.tensor([])\n",
        "  for batch in loader:\n",
        "    images, labels = batch\n",
        "    if i == 1:\n",
        "      images = images.reshape(-1, 32*32*3) \n",
        "    preds = model(images)\n",
        "    all_preds = torch.cat((all_preds, preds) ,dim=0)\n",
        "\n",
        "  return all_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hriKXwiD_n6e"
      },
      "source": [
        "##Testing Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg97FWVO9ZKh"
      },
      "source": [
        "def calc_accuracy(test_preds, test_set, i):\n",
        "  actual_labels = torch.Tensor(test_set.targets)\n",
        "  preds_correct = test_preds.argmax(dim=1).eq(actual_labels).sum().item()\n",
        "  if i == 1:\n",
        "    print('Multi Layer Perceptrons')\n",
        "  else:\n",
        "    print('Convolutional Neural Networks')\n",
        "  print('total correct:', preds_correct)\n",
        "  print('accuracy:', preds_correct / len(test_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXobp6vdAEFS"
      },
      "source": [
        "##Implementation Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2J9o5oWc7st"
      },
      "source": [
        "def main():\n",
        "  train_loader, test_loader, train_set, test_set = cifar_preprocessor(64)\n",
        "  print('Enter 1 for MLP, 2 for CNN')\n",
        "  i = int(input())\n",
        "  if i == 1:\n",
        "\n",
        "    print('Multiple Layer of Perceptrons')\n",
        "    model = MLP_network()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
        "    train_nn(model, train_loader, optimizer, i)\n",
        "    all_preds = get_all_preds(model, test_loader, i)\n",
        "    calc_accuracy(all_preds, test_set, i)\n",
        "    PATH = './cifar100_mlp.pth'\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "\n",
        "  elif i == 2:\n",
        "\n",
        "    print('Convolutional Neural Network')\n",
        "    model = CNN_network()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
        "    train_nn(model, train_loader, optimizer, i)\n",
        "    all_preds = get_all_preds(model, test_loader, i)\n",
        "    calc_accuracy(all_preds, test_set, i)\n",
        "    PATH = './cifar100_cnn.pth'\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "\n",
        "  else:\n",
        "\n",
        "    print('Wrong Choice...Try Again!!!')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmaXfnwjwKIN",
        "outputId": "e7caf27c-1f8e-4bd0-80ec-4a35146d519f"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Enter 1 for MLP, 2 for CNN\n",
            "1\n",
            "Multiple Layer of Perceptrons\n",
            ">>> Training Start >>>\n",
            "epoch: 0 total_correct: 2817 loss: 2342.371166229248\n",
            "epoch: 1 total_correct: 3320 loss: 2340.0113854408264\n",
            "epoch: 2 total_correct: 4354 loss: 2332.8723883628845\n",
            "epoch: 3 total_correct: 4828 loss: 2258.425218820572\n",
            "epoch: 4 total_correct: 6902 loss: 2124.3050644397736\n",
            "epoch: 5 total_correct: 8667 loss: 2058.6139965057373\n",
            "epoch: 6 total_correct: 10074 loss: 1992.6582174301147\n",
            "epoch: 7 total_correct: 11448 loss: 1925.155211687088\n",
            "epoch: 8 total_correct: 12894 loss: 1862.4140621423721\n",
            "epoch: 9 total_correct: 13918 loss: 1809.2699065208435\n",
            "epoch: 10 total_correct: 14919 loss: 1759.2945556640625\n",
            "epoch: 11 total_correct: 16024 loss: 1704.545359969139\n",
            "epoch: 12 total_correct: 16870 loss: 1657.445464372635\n",
            "epoch: 13 total_correct: 17835 loss: 1607.2123988866806\n",
            "epoch: 14 total_correct: 18817 loss: 1554.9647988080978\n",
            "epoch: 15 total_correct: 19625 loss: 1504.4832880496979\n",
            "epoch: 16 total_correct: 20438 loss: 1457.3500571250916\n",
            "epoch: 17 total_correct: 21534 loss: 1401.9261798858643\n",
            "epoch: 18 total_correct: 22502 loss: 1346.6949373483658\n",
            "epoch: 19 total_correct: 23500 loss: 1293.0633860826492\n",
            "epoch: 20 total_correct: 24571 loss: 1238.7428677082062\n",
            "epoch: 21 total_correct: 25787 loss: 1173.1022816300392\n",
            "epoch: 22 total_correct: 26799 loss: 1117.0504439473152\n",
            "epoch: 23 total_correct: 28132 loss: 1050.3701268434525\n",
            "epoch: 24 total_correct: 29300 loss: 991.4318377971649\n",
            "epoch: 25 total_correct: 30446 loss: 928.4249439835548\n",
            "epoch: 26 total_correct: 31757 loss: 865.1841924786568\n",
            "epoch: 27 total_correct: 33180 loss: 796.4853633642197\n",
            "epoch: 28 total_correct: 34014 loss: 754.7700568437576\n",
            "epoch: 29 total_correct: 35392 loss: 689.5142071247101\n",
            ">>> Training Complete >>>\n",
            "Multi Layer Perceptrons\n",
            "total correct: 36676\n",
            "accuracy: 0.73352\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}